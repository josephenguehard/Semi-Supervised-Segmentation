{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from clustering_layer import ClusteringLayer # T-SNE algorithm which is incorporated at the end of the network\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Activation, Input, Dropout, BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.layers.convolutional import Conv3D, Cropping3D\n",
    "from keras.layers.core import Permute, Reshape\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.regularizers import l1_l2\n",
    "from keras.models import Model, load_model\n",
    "K.set_image_dim_ordering('th')\n",
    "from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.image import extract_patches as sk_extract_patches\n",
    "\n",
    "from functions import (config, generate_model, get_filename, get_set_name, read_data, read_vol, save_vol, \n",
    "                       extract_patches, build_set, generate_indexes, reconstruct_volume, target_distribution, \n",
    "                       DSC, save_vol_modif, generate_indexes_modif, reconstruct_volume_modif, read_vol_modif, \n",
    "                       extract_patches_modif, build_set_modif, restartkernel) \n",
    "                       # Functions designed to load images, generate a dataset, and save images\n",
    "\n",
    "(num_classes, patience, model_filename, csv_filename, nb_epoch, validation_split, class_mapper, \n",
    " class_mapper_inv, PATCH_SHAPE, EXTRACTION_SHAPE, n_known) = config() \n",
    "# Config variables set in functions, can be overridden in the Notebook\n",
    "\n",
    "n_known = 11 # Number of images used for the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T1_vols = np.empty((n_known-1, 144, 192, 256))\n",
    "T2_vols = np.empty((n_known-1, 144, 192, 256))\n",
    "label_vols = np.empty((n_known-1, 144, 192, 256))\n",
    "for case_idx in range(1, n_known) :\n",
    "    T1_vols[(case_idx - 1), :, :, :] = read_vol(case_idx, 'T1')\n",
    "    T2_vols[(case_idx - 1), :, :, :] = read_vol(case_idx, 'T2')\n",
    "    label_vols[(case_idx - 1), :, :, :] = read_vol(case_idx, 'label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Intensity normalisation (zero mean and unit variance)\n",
    "T1_mean = T1_vols.mean()\n",
    "T1_std = T1_vols.std()\n",
    "T1_vols = (T1_vols - T1_mean) / T1_std\n",
    "T2_mean = T2_vols.mean()\n",
    "T2_std = T2_vols.std()\n",
    "T2_vols = (T2_vols - T2_mean) / T2_std\n",
    "\n",
    "# Combine labels of BG and CSF\n",
    "for class_idx in class_mapper :\n",
    "    label_vols[label_vols == class_idx] = class_mapper[class_idx]\n",
    "label_vols = label_vols.astype('float16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished segmentation of case # 0\n",
      "Finished segmentation of case # 1\n",
      "Finished segmentation of case # 2\n",
      "Finished segmentation of case # 3\n",
      "Finished segmentation of case # 4\n",
      "Finished segmentation of case # 5\n",
      "Finished segmentation of case # 6\n",
      "Finished segmentation of case # 7\n",
      "Finished segmentation of case # 8\n",
      "Finished segmentation of case # 9\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = build_set(T1_vols, T2_vols, label_vols, (3, 9, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Configure callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The learning rate linearly decreases over the epochs\n",
    "def lr_schedule(ep):\n",
    "    lr = 1e-3\n",
    "    lr *= (nb_epoch - ep)/float(nb_epoch)\n",
    "    print('lr: ', lr)\n",
    "    return lr\n",
    "\n",
    "# Model checkpoint to save the training results\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=model_filename.format(1),\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# CSVLogger to save the training results in a csv file\n",
    "csv_logger = CSVLogger(csv_filename.format(1), separator=';')\n",
    "\n",
    "# Learning rate scheduler\n",
    "learning_rate_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "callbacks = [checkpointer, csv_logger, learning_rate_scheduler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 2, 27, 27, 27 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_27 (Conv3D)              (None, 25, 25, 25, 2 1375        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 25, 25, 25, 2 100         conv3d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_27 (PReLU)              (None, 25, 25, 25, 2 390625      batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_28 (Conv3D)              (None, 25, 23, 23, 2 16900       p_re_lu_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 23, 23, 2 92          conv3d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_28 (PReLU)              (None, 25, 23, 23, 2 304175      batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_29 (Conv3D)              (None, 25, 21, 21, 2 16900       p_re_lu_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 21, 21, 2 84          conv3d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_29 (PReLU)              (None, 25, 21, 21, 2 231525      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_30 (Conv3D)              (None, 50, 19, 19, 1 33800       p_re_lu_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 50, 19, 19, 1 76          conv3d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_30 (PReLU)              (None, 50, 19, 19, 1 342950      batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_31 (Conv3D)              (None, 50, 17, 17, 1 67550       p_re_lu_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 50, 17, 17, 1 68          conv3d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_31 (PReLU)              (None, 50, 17, 17, 1 245650      batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_32 (Conv3D)              (None, 50, 15, 15, 1 67550       p_re_lu_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 50, 15, 15, 1 60          conv3d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_32 (PReLU)              (None, 50, 15, 15, 1 168750      batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_33 (Conv3D)              (None, 75, 13, 13, 1 101325      p_re_lu_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 75, 13, 13, 1 52          conv3d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_33 (PReLU)              (None, 75, 13, 13, 1 164775      batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_34 (Conv3D)              (None, 75, 11, 11, 1 151950      p_re_lu_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 75, 11, 11, 1 44          conv3d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_34 (PReLU)              (None, 75, 11, 11, 1 99825       batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_35 (Conv3D)              (None, 75, 9, 9, 9)  151950      p_re_lu_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 75, 9, 9, 9)  36          conv3d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping3d_5 (Cropping3D)       (None, 25, 9, 9, 9)  0           p_re_lu_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "cropping3d_6 (Cropping3D)       (None, 50, 9, 9, 9)  0           p_re_lu_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_35 (PReLU)              (None, 75, 9, 9, 9)  54675       batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 150, 9, 9, 9) 0           cropping3d_5[0][0]               \n",
      "                                                                 cropping3d_6[0][0]               \n",
      "                                                                 p_re_lu_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_36 (Conv3D)              (None, 400, 9, 9, 9) 60400       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 400, 9, 9, 9) 36          conv3d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_36 (PReLU)              (None, 400, 9, 9, 9) 291600      batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 400, 9, 9, 9) 0           p_re_lu_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_37 (Conv3D)              (None, 200, 9, 9, 9) 80200       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 200, 9, 9, 9) 36          conv3d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_37 (PReLU)              (None, 200, 9, 9, 9) 145800      batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 200, 9, 9, 9) 0           p_re_lu_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_38 (Conv3D)              (None, 150, 9, 9, 9) 30150       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 150, 9, 9, 9) 36          conv3d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_38 (PReLU)              (None, 150, 9, 9, 9) 109350      batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 150, 9, 9, 9) 0           p_re_lu_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_39 (Conv3D)              (None, 3, 9, 9, 9)   453         dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "p_re_lu_39 (PReLU)              (None, 3, 9, 9, 9)   2187        conv3d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 3, 729)       0           p_re_lu_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 729, 3)       0           reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "clustering_layer_3 (ClusteringL (None, 729, 3)       9           permute_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 3,333,119\n",
      "Trainable params: 3,332,759\n",
      "Non-trainable params: 360\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = generate_model(num_classes)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 96749 samples, validate on 24188 samples\n",
      "('lr: ', 0.001)\n",
      "Epoch 1/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.4765 - categorical_accuracy: 0.8505Epoch 00001: val_loss improved from inf to 0.33902, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1318s 14ms/step - loss: 0.4764 - categorical_accuracy: 0.8505 - val_loss: 0.3390 - val_categorical_accuracy: 0.8897\n",
      "('lr: ', 0.00095)\n",
      "Epoch 2/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.2936 - categorical_accuracy: 0.9065Epoch 00002: val_loss improved from 0.33902 to 0.27511, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1316s 14ms/step - loss: 0.2936 - categorical_accuracy: 0.9065 - val_loss: 0.2751 - val_categorical_accuracy: 0.9065\n",
      "('lr: ', 0.0009000000000000001)\n",
      "Epoch 3/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.2530 - categorical_accuracy: 0.9181Epoch 00003: val_loss did not improve\n",
      "96749/96749 [==============================] - 1316s 14ms/step - loss: 0.2530 - categorical_accuracy: 0.9181 - val_loss: 0.2849 - val_categorical_accuracy: 0.9000\n",
      "('lr: ', 0.00085)\n",
      "Epoch 4/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.2349 - categorical_accuracy: 0.9232Epoch 00004: val_loss improved from 0.27511 to 0.24247, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1315s 14ms/step - loss: 0.2349 - categorical_accuracy: 0.9232 - val_loss: 0.2425 - val_categorical_accuracy: 0.9160\n",
      "('lr: ', 0.0008)\n",
      "Epoch 5/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.2209 - categorical_accuracy: 0.9275Epoch 00005: val_loss did not improve\n",
      "96749/96749 [==============================] - 1315s 14ms/step - loss: 0.2209 - categorical_accuracy: 0.9275 - val_loss: 0.2486 - val_categorical_accuracy: 0.9144\n",
      "('lr: ', 0.00075)\n",
      "Epoch 6/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.2112 - categorical_accuracy: 0.9305Epoch 00006: val_loss improved from 0.24247 to 0.24117, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1315s 14ms/step - loss: 0.2112 - categorical_accuracy: 0.9305 - val_loss: 0.2412 - val_categorical_accuracy: 0.9166\n",
      "('lr: ', 0.0007)\n",
      "Epoch 7/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.2047 - categorical_accuracy: 0.9326Epoch 00007: val_loss improved from 0.24117 to 0.23061, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1315s 14ms/step - loss: 0.2047 - categorical_accuracy: 0.9325 - val_loss: 0.2306 - val_categorical_accuracy: 0.9198\n",
      "('lr: ', 0.0006500000000000001)\n",
      "Epoch 8/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1976 - categorical_accuracy: 0.9349Epoch 00008: val_loss improved from 0.23061 to 0.22829, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1315s 14ms/step - loss: 0.1976 - categorical_accuracy: 0.9349 - val_loss: 0.2283 - val_categorical_accuracy: 0.9213\n",
      "('lr: ', 0.0006)\n",
      "Epoch 9/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1926 - categorical_accuracy: 0.9365Epoch 00009: val_loss did not improve\n",
      "96749/96749 [==============================] - 1312s 14ms/step - loss: 0.1926 - categorical_accuracy: 0.9365 - val_loss: 0.2462 - val_categorical_accuracy: 0.9149\n",
      "('lr: ', 0.00055)\n",
      "Epoch 10/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1855 - categorical_accuracy: 0.9388Epoch 00010: val_loss did not improve\n",
      "96749/96749 [==============================] - 1311s 14ms/step - loss: 0.1855 - categorical_accuracy: 0.9388 - val_loss: 0.2312 - val_categorical_accuracy: 0.9197\n",
      "('lr: ', 0.0005)\n",
      "Epoch 11/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1809 - categorical_accuracy: 0.9403Epoch 00011: val_loss improved from 0.22829 to 0.21890, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1312s 14ms/step - loss: 0.1809 - categorical_accuracy: 0.9403 - val_loss: 0.2189 - val_categorical_accuracy: 0.9245\n",
      "('lr: ', 0.00045000000000000004)\n",
      "Epoch 12/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1763 - categorical_accuracy: 0.9418Epoch 00012: val_loss improved from 0.21890 to 0.21433, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1763 - categorical_accuracy: 0.9418 - val_loss: 0.2143 - val_categorical_accuracy: 0.9253\n",
      "('lr: ', 0.0004)\n",
      "Epoch 13/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1706 - categorical_accuracy: 0.9437Epoch 00013: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1706 - categorical_accuracy: 0.9437 - val_loss: 0.2248 - val_categorical_accuracy: 0.9221\n",
      "('lr: ', 0.00035)\n",
      "Epoch 14/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1667 - categorical_accuracy: 0.9449Epoch 00014: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1667 - categorical_accuracy: 0.9449 - val_loss: 0.2170 - val_categorical_accuracy: 0.9254\n",
      "('lr: ', 0.0003)\n",
      "Epoch 15/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1617 - categorical_accuracy: 0.9466Epoch 00015: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1617 - categorical_accuracy: 0.9466 - val_loss: 0.2154 - val_categorical_accuracy: 0.9254\n",
      "('lr: ', 0.00025)\n",
      "Epoch 16/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1573 - categorical_accuracy: 0.9481Epoch 00016: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1573 - categorical_accuracy: 0.9481 - val_loss: 0.2204 - val_categorical_accuracy: 0.9252\n",
      "('lr: ', 0.0002)\n",
      "Epoch 17/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1527 - categorical_accuracy: 0.9497Epoch 00017: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1527 - categorical_accuracy: 0.9497 - val_loss: 0.2227 - val_categorical_accuracy: 0.9240\n",
      "('lr: ', 0.00015)\n",
      "Epoch 18/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1481 - categorical_accuracy: 0.9513Epoch 00018: val_loss improved from 0.21433 to 0.21333, saving model to models/iSeg2017/outrun_step_1.h5\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1481 - categorical_accuracy: 0.9513 - val_loss: 0.2133 - val_categorical_accuracy: 0.9261\n",
      "('lr: ', 0.0001)\n",
      "Epoch 19/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1439 - categorical_accuracy: 0.9528Epoch 00019: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1439 - categorical_accuracy: 0.9528 - val_loss: 0.2179 - val_categorical_accuracy: 0.9258\n",
      "('lr: ', 5e-05)\n",
      "Epoch 20/20\n",
      "96736/96749 [============================>.] - ETA: 0s - loss: 0.1400 - categorical_accuracy: 0.9542Epoch 00020: val_loss did not improve\n",
      "96749/96749 [==============================] - 1313s 14ms/step - loss: 0.1400 - categorical_accuracy: 0.9542 - val_loss: 0.2205 - val_categorical_accuracy: 0.9264\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "model = generate_model(num_classes)\n",
    "\n",
    "# Train model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=nb_epoch,\n",
    "    validation_split=validation_split,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "# freeing space\n",
    "del x_train\n",
    "del y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load best model according to the validation set\n",
    "model = generate_model(num_classes)\n",
    "model.load_weights(model_filename.format(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished segmentation of case # 6\n",
      "Finished segmentation of case # 7\n",
      "Finished segmentation of case # 8\n",
      "Finished segmentation of case # 9\n",
      "Finished segmentation of case # 10\n",
      "Finished segmentation of case # 11\n",
      "Finished segmentation of case # 12\n",
      "Finished segmentation of case # 13\n",
      "Finished segmentation of case # 14\n",
      "Finished segmentation of case # 15\n",
      "Finished segmentation of case # 16\n",
      "Finished segmentation of case # 17\n",
      "Finished segmentation of case # 18\n",
      "Finished segmentation of case # 19\n",
      "Finished segmentation of case # 20\n",
      "Finished segmentation of case # 21\n",
      "Finished segmentation of case # 22\n",
      "Finished segmentation of case # 23\n",
      "Done with Step 1\n"
     ]
    }
   ],
   "source": [
    "# Save segmentations of the test set\n",
    "for case_idx in range(6,24) :\n",
    "    T1_test_vol = read_vol(case_idx, 'T1')[:144, :192, :256]\n",
    "    T2_test_vol = read_vol(case_idx, 'T2')[:144, :192, :256]\n",
    "\n",
    "    x_test = np.zeros((6916, 2, PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE))\n",
    "    x_test[:, 0, :, :, :] = extract_patches(T1_test_vol, \n",
    "                                            patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                            extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "    x_test[:, 1, :, :, :] = extract_patches(T2_test_vol, \n",
    "                                            patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                            extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "\n",
    "    x_test[:, 0, :, :, :] = (x_test[:, 0, :, :, :] - T1_mean) / T1_std\n",
    "    x_test[:, 1, :, :, :] = (x_test[:, 1, :, :, :] - T2_mean) / T2_std\n",
    "\n",
    "    pred = model.predict(x_test, verbose=2)\n",
    "    pred = np.argmax(pred, axis=2)\n",
    "    pred = pred.reshape((len(pred), EXTRACTION_SHAPE, EXTRACTION_SHAPE, \n",
    "                                         EXTRACTION_SHAPE))\n",
    "    segmentation = reconstruct_volume(pred, (144, 192, 256))\n",
    "\n",
    "    csf = np.logical_and(segmentation == 0, T1_test_vol != 0)\n",
    "    segmentation[segmentation == 2] = 250\n",
    "    segmentation[segmentation == 1] = 150\n",
    "    segmentation[csf] = 10\n",
    "\n",
    "    save_vol(segmentation, case_idx)\n",
    "\n",
    "    print(\"Finished segmentation of case # {}\".format(case_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('case_idx: ', 6)\n",
      "(10, ':', 0.9682849707585975)\n",
      "(150, ':', 0.9398487499247111)\n",
      "(250, ':', 0.9282338514851699)\n",
      "('average : ', 0.9454558573894928)\n",
      "('case_idx: ', 7)\n",
      "(10, ':', 0.966125824136991)\n",
      "(150, ':', 0.9417523289756555)\n",
      "(250, ':', 0.931827292663947)\n",
      "('average : ', 0.9465684819255312)\n",
      "('case_idx: ', 8)\n",
      "(10, ':', 0.9696613913192658)\n",
      "(150, ':', 0.9432344694894719)\n",
      "(250, ':', 0.9292195374811059)\n",
      "('average : ', 0.9473717994299479)\n",
      "('case_idx: ', 9)\n",
      "(10, ':', 0.9418968079110519)\n",
      "(150, ':', 0.9067204616477362)\n",
      "(250, ':', 0.9025529804386385)\n",
      "('average : ', 0.9170567499991421)\n",
      "('case_idx: ', 10)\n",
      "(10, ':', 0.9531112812084919)\n",
      "(150, ':', 0.9073739758366893)\n",
      "(250, ':', 0.8606722000204939)\n",
      "('average : ', 0.9070524856885585)\n"
     ]
    }
   ],
   "source": [
    "# Print segmentation scores of 5 images\n",
    "for case_idx in range(6,11):\n",
    "    im1 = read_data(case_idx, 'label', 'datasets')\n",
    "    im2 = read_data(case_idx, 'label', 'results')\n",
    "    im1 = im1.get_data()\n",
    "    im2 = im2.get_data()\n",
    "\n",
    "    x = []\n",
    "    print('case_idx: ', case_idx)\n",
    "    for i in [10, 150, 250]:\n",
    "        x.append(DSC(im1, im2, i))\n",
    "        print(i, ':', DSC(im1, im2, i))\n",
    "    print('average : ', np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished segmentation of case # 1\n",
      "Finished segmentation of case # 2\n",
      "Finished segmentation of case # 3\n",
      "Finished segmentation of case # 4\n",
      "Finished segmentation of case # 5\n",
      "Finished segmentation of case # 6\n",
      "Finished segmentation of case # 7\n",
      "Finished segmentation of case # 8\n",
      "Finished segmentation of case # 9\n",
      "Finished segmentation of case # 10\n",
      "Finished segmentation of case # 11\n",
      "Finished segmentation of case # 12\n",
      "Finished segmentation of case # 13\n",
      "Finished segmentation of case # 14\n",
      "Finished segmentation of case # 15\n",
      "Finished segmentation of case # 16\n",
      "Finished segmentation of case # 17\n",
      "Finished segmentation of case # 18\n",
      "Finished segmentation of case # 19\n",
      "Finished segmentation of case # 20\n",
      "Finished segmentation of case # 21\n",
      "Finished segmentation of case # 22\n",
      "Finished segmentation of case # 23\n",
      "Done with Step 1\n"
     ]
    }
   ],
   "source": [
    "# Save probabilities results for the whole dataset (train and test)\n",
    "# Differently from previously, for each voxel, 3 probabilities are recorded\n",
    "# This data is necessary as we use soft labels for semi-supervised training\n",
    "for case_idx in range(1, 24) :\n",
    "    T1_test_vol = read_vol(case_idx, 'T1')[:144, :192, :256]\n",
    "    T2_test_vol = read_vol(case_idx, 'T2')[:144, :192, :256]\n",
    "\n",
    "    x_test = np.zeros((6916, 2, PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE))\n",
    "    x_test[:, 0, :, :, :] = extract_patches(T1_test_vol, \n",
    "                                            patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                            extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "    x_test[:, 1, :, :, :] = extract_patches(T2_test_vol, \n",
    "                                            patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                            extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "\n",
    "    x_test[:, 0, :, :, :] = (x_test[:, 0, :, :, :] - T1_mean) / T1_std\n",
    "    x_test[:, 1, :, :, :] = (x_test[:, 1, :, :, :] - T2_mean) / T2_std\n",
    "\n",
    "    pred = model.predict(x_test, verbose=2)\n",
    "    pred = target_distribution(pred)\n",
    "    pred = pred.reshape((len(pred), EXTRACTION_SHAPE, EXTRACTION_SHAPE, \n",
    "                                         EXTRACTION_SHAPE, num_classes))\n",
    "    segmentation = reconstruct_volume_modif(pred, (144, 192, 256, num_classes))\n",
    "    \n",
    "    save_vol_modif(segmentation, case_idx)\n",
    "\n",
    "    print(\"Finished segmentation of case # {}\".format(case_idx))\n",
    "\n",
    "print(\"Done with Step 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Freeing space before set 2\n",
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Semi-supervised step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2747\n",
      "Finished segmentation of case # 0\n",
      "2334\n",
      "Finished segmentation of case # 1\n",
      "2443\n",
      "Finished segmentation of case # 2\n",
      "2122\n",
      "Finished segmentation of case # 3\n",
      "2603\n",
      "Finished segmentation of case # 4\n",
      "1292\n",
      "Finished segmentation of case # 0\n",
      "1339\n",
      "Finished segmentation of case # 1\n",
      "1331\n",
      "Finished segmentation of case # 2\n",
      "1459\n",
      "Finished segmentation of case # 3\n",
      "1277\n",
      "Finished segmentation of case # 4\n",
      "1291\n",
      "Finished segmentation of case # 5\n",
      "1205\n",
      "Finished segmentation of case # 6\n",
      "1499\n",
      "Finished segmentation of case # 7\n",
      "1321\n",
      "Finished segmentation of case # 8\n",
      "1335\n",
      "Finished segmentation of case # 9\n",
      "1507\n",
      "Finished segmentation of case # 10\n",
      "1108\n",
      "Finished segmentation of case # 11\n",
      "1335\n",
      "Finished segmentation of case # 12\n",
      "1306\n",
      "Finished segmentation of case # 13\n",
      "1518\n",
      "Finished segmentation of case # 14\n",
      "1293\n",
      "Finished segmentation of case # 15\n",
      "1529\n",
      "Finished segmentation of case # 16\n",
      "1309\n",
      "Finished segmentation of case # 17\n",
      "Train on 29202 samples, validate on 7301 samples\n",
      "lr:  0.001\n",
      "Epoch 1/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.6388 - categorical_accuracy: 0.7990Epoch 00001: val_loss improved from inf to 0.45555, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 396s 14ms/step - loss: 0.6387 - categorical_accuracy: 0.7990 - val_loss: 0.4555 - val_categorical_accuracy: 0.8274\n",
      "lr:  0.00095\n",
      "Epoch 2/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.3519 - categorical_accuracy: 0.8889Epoch 00002: val_loss improved from 0.45555 to 0.31131, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 395s 14ms/step - loss: 0.3518 - categorical_accuracy: 0.8889 - val_loss: 0.3113 - val_categorical_accuracy: 0.8809\n",
      "lr:  0.0009\n",
      "Epoch 3/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.2876 - categorical_accuracy: 0.9051Epoch 00003: val_loss improved from 0.31131 to 0.22111, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.2876 - categorical_accuracy: 0.9051 - val_loss: 0.2211 - val_categorical_accuracy: 0.9173\n",
      "lr:  0.00085\n",
      "Epoch 4/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.2508 - categorical_accuracy: 0.9156Epoch 00004: val_loss improved from 0.22111 to 0.21202, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.2508 - categorical_accuracy: 0.9156 - val_loss: 0.2120 - val_categorical_accuracy: 0.9137\n",
      "lr:  0.0008\n",
      "Epoch 5/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.2285 - categorical_accuracy: 0.9216Epoch 00005: val_loss improved from 0.21202 to 0.21120, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.2284 - categorical_accuracy: 0.9216 - val_loss: 0.2112 - val_categorical_accuracy: 0.9115\n",
      "lr:  0.00075\n",
      "Epoch 6/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.2118 - categorical_accuracy: 0.9262Epoch 00006: val_loss improved from 0.21120 to 0.19202, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.2118 - categorical_accuracy: 0.9262 - val_loss: 0.1920 - val_categorical_accuracy: 0.9177\n",
      "lr:  0.0007\n",
      "Epoch 7/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.2010 - categorical_accuracy: 0.9289Epoch 00007: val_loss did not improve\n",
      "29202/29202 [==============================] - 394s 14ms/step - loss: 0.2010 - categorical_accuracy: 0.9289 - val_loss: 0.2083 - val_categorical_accuracy: 0.9082\n",
      "lr:  0.00065\n",
      "Epoch 8/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1885 - categorical_accuracy: 0.9327Epoch 00008: val_loss improved from 0.19202 to 0.15176, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 14ms/step - loss: 0.1885 - categorical_accuracy: 0.9327 - val_loss: 0.1518 - val_categorical_accuracy: 0.9348\n",
      "lr:  0.0006\n",
      "Epoch 9/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1815 - categorical_accuracy: 0.9344Epoch 00009: val_loss did not improve\n",
      "29202/29202 [==============================] - 394s 14ms/step - loss: 0.1815 - categorical_accuracy: 0.9344 - val_loss: 0.1748 - val_categorical_accuracy: 0.9238\n",
      "lr:  0.00055\n",
      "Epoch 10/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1742 - categorical_accuracy: 0.9365Epoch 00010: val_loss improved from 0.15176 to 0.14573, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 14ms/step - loss: 0.1741 - categorical_accuracy: 0.9365 - val_loss: 0.1457 - val_categorical_accuracy: 0.9347\n",
      "lr:  0.0005\n",
      "Epoch 11/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1677 - categorical_accuracy: 0.9385Epoch 00011: val_loss did not improve\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1677 - categorical_accuracy: 0.9384 - val_loss: 0.1517 - val_categorical_accuracy: 0.9315\n",
      "lr:  0.00045\n",
      "Epoch 12/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1618 - categorical_accuracy: 0.9401Epoch 00012: val_loss improved from 0.14573 to 0.13835, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1618 - categorical_accuracy: 0.9401 - val_loss: 0.1383 - val_categorical_accuracy: 0.9370\n",
      "lr:  0.0004\n",
      "Epoch 13/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1569 - categorical_accuracy: 0.9416Epoch 00013: val_loss did not improve\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1569 - categorical_accuracy: 0.9416 - val_loss: 0.1604 - val_categorical_accuracy: 0.9259\n",
      "lr:  0.00035\n",
      "Epoch 14/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1520 - categorical_accuracy: 0.9431Epoch 00014: val_loss improved from 0.13835 to 0.13291, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 14ms/step - loss: 0.1520 - categorical_accuracy: 0.9432 - val_loss: 0.1329 - val_categorical_accuracy: 0.9390\n",
      "lr:  0.0003\n",
      "Epoch 15/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1479 - categorical_accuracy: 0.9444Epoch 00015: val_loss did not improve\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1480 - categorical_accuracy: 0.9444 - val_loss: 0.1388 - val_categorical_accuracy: 0.9357\n",
      "lr:  0.00025\n",
      "Epoch 16/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1427 - categorical_accuracy: 0.9464Epoch 00016: val_loss improved from 0.13291 to 0.12970, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1427 - categorical_accuracy: 0.9464 - val_loss: 0.1297 - val_categorical_accuracy: 0.9386\n",
      "lr:  0.0002\n",
      "Epoch 17/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1396 - categorical_accuracy: 0.9473Epoch 00017: val_loss improved from 0.12970 to 0.12619, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1396 - categorical_accuracy: 0.9473 - val_loss: 0.1262 - val_categorical_accuracy: 0.9403\n",
      "lr:  0.00015\n",
      "Epoch 18/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1360 - categorical_accuracy: 0.9486Epoch 00018: val_loss improved from 0.12619 to 0.12245, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1360 - categorical_accuracy: 0.9486 - val_loss: 0.1224 - val_categorical_accuracy: 0.9420\n",
      "lr:  0.0001\n",
      "Epoch 19/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1326 - categorical_accuracy: 0.9498Epoch 00019: val_loss improved from 0.12245 to 0.12036, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1326 - categorical_accuracy: 0.9498 - val_loss: 0.1204 - val_categorical_accuracy: 0.9426\n",
      "lr:  5e-05\n",
      "Epoch 20/20\n",
      "29184/29202 [============================>.] - ETA: 0s - loss: 0.1296 - categorical_accuracy: 0.9511Epoch 00020: val_loss improved from 0.12036 to 0.11906, saving model to models/iSeg2017/outrun_step_2.h5\n",
      "29202/29202 [==============================] - 394s 13ms/step - loss: 0.1296 - categorical_accuracy: 0.9511 - val_loss: 0.1191 - val_categorical_accuracy: 0.9433\n",
      "Finished segmentation of case # 6\n",
      "Finished segmentation of case # 7\n",
      "Finished segmentation of case # 8\n",
      "Finished segmentation of case # 9\n",
      "Finished segmentation of case # 10\n",
      "Done with Step 2\n",
      "('case_idx: ', 6)\n",
      "(10, ':', 0.94185819768271)\n",
      "(150, ':', 0.9106206492835901)\n",
      "(250, ':', 0.8999659828288166)\n",
      "('average : ', 0.9174816099317056)\n",
      "('case_idx: ', 7)\n",
      "(10, ':', 0.9204744258122421)\n",
      "(150, ':', 0.8805191885069716)\n",
      "(250, ':', 0.8657058077103199)\n",
      "('average : ', 0.8888998073431779)\n",
      "('case_idx: ', 8)\n",
      "(10, ':', 0.9573408966731006)\n",
      "(150, ':', 0.9179215548355262)\n",
      "(250, ':', 0.8963899715168883)\n",
      "('average : ', 0.923884141008505)\n",
      "('case_idx: ', 9)\n",
      "(10, ':', 0.9436480899619646)\n",
      "(150, ':', 0.9053697605368639)\n",
      "(250, ':', 0.8977603069426954)\n",
      "('average : ', 0.9155927191471745)\n",
      "('case_idx: ', 10)\n",
      "(10, ':', 0.9487566398311368)\n",
      "(150, ':', 0.904804481650868)\n",
      "(250, ':', 0.8559726997250093)\n",
      "('average : ', 0.9031779404023381)\n",
      "Finished segmentation of case # 6\n",
      "Finished segmentation of case # 7\n",
      "Finished segmentation of case # 8\n",
      "Finished segmentation of case # 9\n",
      "Finished segmentation of case # 10\n",
      "Finished segmentation of case # 11\n",
      "Finished segmentation of case # 12\n",
      "Finished segmentation of case # 13\n",
      "Finished segmentation of case # 14\n",
      "Finished segmentation of case # 15\n",
      "Finished segmentation of case # 16\n",
      "Finished segmentation of case # 17\n",
      "Finished segmentation of case # 18\n",
      "Finished segmentation of case # 19\n",
      "Finished segmentation of case # 20\n",
      "Finished segmentation of case # 21\n",
      "Finished segmentation of case # 22\n",
      "Finished segmentation of case # 23\n",
      "Done with Step 2\n"
     ]
    }
   ],
   "source": [
    "# The step 2 can be run until the score doesn't increase further\n",
    "numiter = 10\n",
    "for ite in range(numiter):\n",
    "    \n",
    "    import nibabel as nib\n",
    "    import numpy as np\n",
    "\n",
    "    from clustering_layer import ClusteringLayer # T-SNE algorithm which is incorporated at the end of the network\n",
    "\n",
    "    from keras import backend as K\n",
    "    from keras.layers import Activation, Input, Dropout, BatchNormalization\n",
    "    from keras.layers.advanced_activations import PReLU\n",
    "    from keras.layers.convolutional import Conv3D, Cropping3D\n",
    "    from keras.layers.core import Permute, Reshape\n",
    "    from keras.layers.merge import concatenate\n",
    "    from keras.regularizers import l1_l2\n",
    "    from keras.models import Model, load_model\n",
    "    K.set_image_dim_ordering('th')\n",
    "    from keras.callbacks import ModelCheckpoint, CSVLogger, EarlyStopping, LearningRateScheduler\n",
    "    from keras.utils import np_utils\n",
    "\n",
    "    import itertools\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.feature_extraction.image import extract_patches as sk_extract_patches\n",
    "\n",
    "    from functions import (config, generate_model, get_filename, get_set_name, read_data, read_vol, save_vol, \n",
    "                           extract_patches, build_set, generate_indexes, reconstruct_volume, target_distribution, \n",
    "                           DSC, save_vol_modif, generate_indexes_modif, reconstruct_volume_modif, read_vol_modif, \n",
    "                           extract_patches_modif, build_set_modif, restartkernel) \n",
    "                           # Functions designed to load images, generate a dataset, and save images\n",
    "\n",
    "    (num_classes, patience, model_filename, csv_filename, nb_epoch, validation_split, class_mapper, \n",
    "     class_mapper_inv, PATCH_SHAPE, EXTRACTION_SHAPE, n_known) = config() \n",
    "    # Config variables set in functions, can be overridden in the Notebook\n",
    "\n",
    "    n_known = 11 # Number of images used for the training set\n",
    "    \n",
    "    from keras.utils import to_categorical\n",
    "    \n",
    "    # sets of training and testing images\n",
    "    sure = range(n_known-1)\n",
    "    unsure = range(n_known-1, 23)\n",
    "    \n",
    "    T1_vols = np.empty((23, 144, 192, 256), dtype='float32')\n",
    "    T2_vols = np.empty((23, 144, 192, 256), dtype='float32')\n",
    "    label_vols = np.empty((23, 144, 192, 256, 3), dtype='float16')\n",
    "\n",
    "    # For the testing set, we load the segmentations results instead of the (unknown) true labels\n",
    "    for case_idx in range(n_known, 24) :\n",
    "        loc = 'results'\n",
    "\n",
    "        T1_vols[(case_idx - 1), :, :, :] = read_vol_modif(case_idx, 'T1')[:144, :192, :256, 0]\n",
    "        T2_vols[(case_idx - 1), :, :, :] = read_vol_modif(case_idx, 'T2')[:144, :192, :256, 0]\n",
    "        label_vols[(case_idx - 1), :, :, :] = read_vol_modif(case_idx, 'label', loc)[:144, :192, :256]\n",
    "        print(case_idx)\n",
    "\n",
    "    # For the training set, we load the true labels\n",
    "    for case_idx in range(1, n_known) :\n",
    "        loc = 'datasets'\n",
    "\n",
    "        T1_vols[(case_idx - 1), :, :, :] = read_vol_modif(case_idx, 'T1')[:144, :192, :256, 0]\n",
    "        T2_vols[(case_idx - 1), :, :, :] = read_vol_modif(case_idx, 'T2')[:144, :192, :256, 0]\n",
    "        x = read_vol_modif(case_idx, 'label', loc)[:144, :192, :256]\n",
    "        for class_idx in class_mapper :\n",
    "            x[x == class_idx] = class_mapper[class_idx]\n",
    "        label_vols[(case_idx - 1)] = to_categorical(x)\n",
    "        print(case_idx)\n",
    "        \n",
    "    T1_vols = T1_vols.astype('float32')\n",
    "    T2_vols = T2_vols.astype('float32')\n",
    "    label_vols = label_vols.astype('float16')\n",
    "    \n",
    "    ## Intensity normalisation (zero mean and unit variance)\n",
    "    T1_mean = T1_vols.mean()\n",
    "    T1_std = T1_vols.std()\n",
    "    T1_vols = (T1_vols - T1_mean) / T1_std\n",
    "    T2_mean = T2_vols.mean()\n",
    "    T2_std = T2_vols.std()\n",
    "    T2_vols = (T2_vols - T2_mean) / T2_std\n",
    "    \n",
    "    # Build sets\n",
    "    x_sure, y_sure = build_set_modif(T1_vols[sure], T2_vols[sure], label_vols[sure], n_known, False, (3, 9, 3))\n",
    "    x_unsure, y_unsure = build_set_modif(T1_vols[unsure], T2_vols[unsure], label_vols[unsure], n_known, True)\n",
    "\n",
    "    x_train = np.vstack((x_sure, x_unsure))\n",
    "    y_train = np.vstack((y_sure, y_unsure))\n",
    "\n",
    "    # Freeing space\n",
    "    del x_sure\n",
    "    del x_unsure\n",
    "    del y_sure\n",
    "    del y_unsure\n",
    "    \n",
    "    # The learning rate linearly decreases over the epochs\n",
    "    def lr_schedule(ep):\n",
    "        lr = 1e-3\n",
    "        lr *= (nb_epoch - ep)/float(nb_epoch)\n",
    "        print 'lr: ', lr\n",
    "        return lr\n",
    "\n",
    "    # Model checkpoint to save the training results\n",
    "    checkpointer = ModelCheckpoint(\n",
    "        filepath=model_filename.format(2),\n",
    "        verbose=1,\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True)\n",
    "\n",
    "    # CSVLogger to save the training results in a csv file\n",
    "    csv_logger = CSVLogger(csv_filename.format(2), separator=';')\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    learning_rate_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    callbacks = [checkpointer, csv_logger, learning_rate_scheduler]\n",
    "    \n",
    "    # Build model\n",
    "    model = generate_model(num_classes)\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        epochs=nb_epoch,\n",
    "        validation_split=validation_split,\n",
    "        verbose=1,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    # freeing space\n",
    "    del x_train\n",
    "    del y_train\n",
    "\n",
    "    # Load best model\n",
    "    model = generate_model(num_classes)\n",
    "    model.load_weights(model_filename.format(2))\n",
    "    \n",
    "    # Save segmentation results for 5 images\n",
    "    for case_idx in range(6, 11) :\n",
    "        T1_test_vol = read_vol(case_idx, 'T1')[:144, :192, :256]\n",
    "        T2_test_vol = read_vol(case_idx, 'T2')[:144, :192, :256]\n",
    "\n",
    "        x_test = np.zeros((6916, 2, PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE))\n",
    "        x_test[:, 0, :, :, :] = extract_patches(T1_test_vol, \n",
    "                                                patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                                extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "        x_test[:, 1, :, :, :] = extract_patches(T2_test_vol, \n",
    "                                                patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                                extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "\n",
    "        x_test[:, 0, :, :, :] = (x_test[:, 0, :, :, :] - T1_mean) / T1_std\n",
    "        x_test[:, 1, :, :, :] = (x_test[:, 1, :, :, :] - T2_mean) / T2_std\n",
    "\n",
    "        pred = model.predict(x_test, verbose=2)\n",
    "        pred_classes = np.argmax(pred, axis=2)\n",
    "        pred_classes = pred_classes.reshape((len(pred_classes), EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "        segmentation = reconstruct_volume(pred_classes, (144, 192, 256))\n",
    "\n",
    "        csf = np.logical_and(segmentation == 0, T1_test_vol != 0)\n",
    "        segmentation[segmentation == 2] = 250\n",
    "        segmentation[segmentation == 1] = 150\n",
    "        segmentation[csf] = 10\n",
    "\n",
    "        save_vol(segmentation, case_idx, 'refined-results')\n",
    "\n",
    "        print \"Finished segmentation of case # {}\".format(case_idx)\n",
    "        \n",
    "    # Print Dice score for these images\n",
    "    for case_idx in range(6, 11):\n",
    "        im1 = read_data(case_idx, 'label', 'datasets')\n",
    "        im2 = read_data(case_idx, 'label', 'refined-results')\n",
    "        im1 = im1.get_data()\n",
    "        im2 = im2.get_data()\n",
    "\n",
    "        x = []\n",
    "        print('case_idx: ', case_idx)\n",
    "        for i in [10, 150, 250]:\n",
    "            x.append(DSC(im1, im2, i))\n",
    "            print(i, ':', DSC(im1, im2, i))\n",
    "        print('average : ', np.mean(x))\n",
    "    \n",
    "    # Save probabilities results to be used as soft labels for the next iteration\n",
    "    for case_idx in range(n_known,24) :\n",
    "        T1_test_vol = read_vol(case_idx, 'T1')[:144, :192, :256]\n",
    "        T2_test_vol = read_vol(case_idx, 'T2')[:144, :192, :256]\n",
    "\n",
    "        x_test = np.zeros((6916, 2, PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE))\n",
    "        x_test[:, 0, :, :, :] = extract_patches(T1_test_vol, \n",
    "                                                patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                                extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "        x_test[:, 1, :, :, :] = extract_patches(T2_test_vol, \n",
    "                                                patch_shape=(PATCH_SHAPE, PATCH_SHAPE, PATCH_SHAPE), \n",
    "                                                extraction_step=(EXTRACTION_SHAPE, EXTRACTION_SHAPE, EXTRACTION_SHAPE))\n",
    "\n",
    "        x_test[:, 0, :, :, :] = (x_test[:, 0, :, :, :] - T1_mean) / T1_std\n",
    "        x_test[:, 1, :, :, :] = (x_test[:, 1, :, :, :] - T2_mean) / T2_std\n",
    "\n",
    "        pred = model.predict(x_test, verbose=2)\n",
    "        pred = target_distribution(pred)\n",
    "        pred = pred.reshape((len(pred), EXTRACTION_SHAPE, EXTRACTION_SHAPE, \n",
    "                                             EXTRACTION_SHAPE, num_classes))\n",
    "        segmentation = reconstruct_volume_modif(pred, (144, 192, 256, num_classes))\n",
    "\n",
    "        save_vol_modif(segmentation, case_idx)\n",
    "\n",
    "        print(\"Finished segmentation of case # {}\".format(case_idx))\n",
    "        \n",
    "    # Freeing space\n",
    "    %reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
